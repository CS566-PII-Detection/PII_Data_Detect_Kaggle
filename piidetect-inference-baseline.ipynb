{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"},{"sourceId":164326253,"sourceType":"kernelVersion"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Training Notebook\nâ€‹\n# Overview\n    - Ran on kaggle CPU\n    - Model fined using https://www.kaggle.com/code/jonathankasprisin/piidetect-training-baseline/edit\n# To try\nI retrained the model with new data selection and data cleaning\nDoing this brought the LB score to .888 - Trained in Kaggle Notebook, no tricks or secrets.\nI got .890 by adding the trick decscribed here: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470978 https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470978\nAdding more data by PJ Mathematician (https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470921) increased to .893\n\nchanging lr to 2e-5 (before 5e-5) increased to .903\n\n# Credit\n- https://www.kaggle.com/code/valentinwerner/915-deberta3base-inference","metadata":{}},{"cell_type":"markdown","source":"## Config and import","metadata":{}},{"cell_type":"code","source":"#Submission vs Cross Validation Flag\nSUBMISSION = False","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:58:24.075858Z","iopub.execute_input":"2024-03-01T23:58:24.076380Z","iopub.status.idle":"2024-03-01T23:58:24.083379Z","shell.execute_reply.started":"2024-03-01T23:58:24.076348Z","shell.execute_reply":"2024-03-01T23:58:24.081482Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nimport os\n\nimport json\nimport argparse\nfrom itertools import chain\nfrom functools import partial\n\nimport torch\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\nfrom datasets import Dataset, features\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:46:36.097014Z","iopub.execute_input":"2024-03-01T23:46:36.097581Z","iopub.status.idle":"2024-03-01T23:46:36.107338Z","shell.execute_reply.started":"2024-03-01T23:46:36.097517Z","shell.execute_reply":"2024-03-01T23:46:36.104651Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = '../input/pii-detection-removal-from-educational-data'\nINFERENCE_MODEL_PATH = \"/kaggle/input/piidetect-training-baseline/deberta3base_pii2d_1024_v1\"\nINFERENCE_MAX_LENGTH = 1024\nOUTPUT_DIR = \"/kaggle/working/\"\n\n#print files with pathname\nfor dirname, _, filenames in os.walk(DATA_PATH):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:24:53.879255Z","iopub.execute_input":"2024-03-01T23:24:53.880018Z","iopub.status.idle":"2024-03-01T23:24:53.887760Z","shell.execute_reply.started":"2024-03-01T23:24:53.879979Z","shell.execute_reply":"2024-03-01T23:24:53.886577Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"../input/pii-detection-removal-from-educational-data/sample_submission.csv\n../input/pii-detection-removal-from-educational-data/train.json\n../input/pii-detection-removal-from-educational-data/test.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Tokenizer from Training","metadata":{}},{"cell_type":"code","source":"def infer_tokenize(example, tokenizer):\n    \"\"\"\n    Tokenize an example for NER using the given tokenizer.\n\n    Args:\n        example (dict): A dictionary containing \"tokens\" and \"trailing_whitespace\" lists.\n            - \"tokens\": A list of token strings.\n            - \"trailing_whitespace\": A list of boolean values indicating whether each token has trailing whitespace.\n        tokenizer: The tokenizer to use for tokenization.\n\n    Returns:\n        dict: A dictionary containing tokenized output, including offsets mapping and token map.\n            - \"input_ids\": List of token IDs.\n            - \"attention_mask\": List of attention mask values.\n            - \"offset_mapping\": List of character offsets for each token.\n            - \"token_map\": List mapping each input token to its original position in the example.\n            \n    Reference: https://www.kaggle.com/code/valentinwerner/893-deberta3base-Inference\n    \"\"\"\n    #construct text and mapping of token to text location\n    text = []\n    token_map = []\n    \n    idx = 0\n    \n    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n        \n        text.append(t)\n        token_map.extend([idx]*len(t))\n        if ws:\n            text.append(\" \")\n            #no token label if it is white space\n            token_map.append(-1)\n            \n        idx += 1\n        \n        \n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=INFERENCE_MAX_LENGTH)\n    \n        \n    return {\n        **tokenized,\n        \"token_map\": token_map,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:37:46.600143Z","iopub.execute_input":"2024-03-01T23:37:46.601141Z","iopub.status.idle":"2024-03-01T23:37:46.614349Z","shell.execute_reply.started":"2024-03-01T23:37:46.601088Z","shell.execute_reply":"2024-03-01T23:37:46.611622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Load Data and Model","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(INFERENCE_MODEL_PATH)\n\nmodel = AutoModelForTokenClassification.from_pretrained(INFERENCE_MODEL_PATH)\ncollator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:37:50.560967Z","iopub.execute_input":"2024-03-01T23:37:50.562168Z","iopub.status.idle":"2024-03-01T23:37:51.842176Z","shell.execute_reply.started":"2024-03-01T23:37:50.562012Z","shell.execute_reply":"2024-03-01T23:37:51.840770Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#data from orginal training json\nif SUBMISSION:\n    data = json.load(open(DATA_PATH+ \"/test.json\"))\nelse: \n    #TODO: make validation set \"/validation.json\"\n    data = json.load(open(DATA_PATH+\"/train.json\"))\n\n#convert to hugging face Dataset object\nds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data],\n    \"document\": [str(x[\"document\"]) for x in data],\n    \"tokens\": [x[\"tokens\"] for x in data],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data]\n})\n\n# Map the tokenize function to your dataset\nds = ds.map(\n    infer_tokenize,\n    fn_kwargs={      # pass keyword args\n        \"tokenizer\": tokenizer\n    }, \n    num_proc=1   #issue with multithreading so went with 1\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T00:01:46.326892Z","iopub.execute_input":"2024-03-02T00:01:46.327471Z","iopub.status.idle":"2024-03-02T00:04:31.645708Z","shell.execute_reply.started":"2024-03-02T00:01:46.327425Z","shell.execute_reply":"2024-03-02T00:04:31.644672Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6807 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48cb489896804e7eaed2bc53a2db13c9"}},"metadata":{}}]},{"cell_type":"code","source":"#Configure trainer\ntraining_args = TrainingArguments(\n    output_dir= OUTPUT_DIR,  # Directory to save checkpoints and logs\n    #fp16 =True,               #mix-precision training on 16 bit to reduce memory and speed up training\n    #learning_rate=2e-5,       # intial learning rate\n    gradient_accumulation_steps=2,  #how many batches to acculumate gradient before optimization if batch size limited by GPU memory\n    report_to=\"none\",        #where training report progress, \"none\" prevents wandb login\n    num_train_epochs=3,      # Number of training epochs\n    #per_device_train_batch_size=4,  # Batch size based per GPU\n    per_device_eval_batch_size=1,\n    #save_steps=500,          # Save model checkpoints every X steps\n    do_eval = False,          #whether or not to perform eval during training\n    evaluation_strategy=\"no\",    # When to evaluate during training {no, steps or epoch}\n    #eval_steps=100,          # Evaluate every X steps if stretegy is \"steps\"\n    #logging_dir=OUTPUT_DIR+\"/logs\",    # Directory to save training logs\n    logging_steps=100,       # Log training progress every X steps\n    #load_best_model_at_end=True,   # Load the best model at the end of training\n    metric_for_best_model=\"f5\",  # Metric to determine the best model (\"accuracy\", f1...)\n    #greater_is_better=True,      # if higher eval metric is better. True for f1 and acc\n    save_total_limit=1,      # how many checkpoints to keep at end (1 means most recent)\n    #lr_scheduler_type='cosine', #\n    #warmup_ratio=0.1,           #steps to gradually increase learning rate. can help stabalize training at begining\n    #weight_decay=0.01,          # l2 regularization to prevent overfitting\n    \n)\n\n#inialize trainer for training and evaluation interface\ntrainer = Trainer(\n    model=model, \n    args=training_args, \n    data_collator=collator, \n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:43:39.227180Z","iopub.execute_input":"2024-03-01T23:43:39.227618Z","iopub.status.idle":"2024-03-01T23:43:39.246373Z","shell.execute_reply.started":"2024-03-01T23:43:39.227586Z","shell.execute_reply":"2024-03-01T23:43:39.245136Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"#get predictions from model\npredictions = trainer.predict(ds).predictions\n\n#scale to probilities for interpretability\npred_softmax = np.exp(predictions) / np.sum(np.exp(predictions), axis = 2).reshape(predictions.shape[0],predictions.shape[1],1)\n\n#load id2label configuration from model\nconfig = json.load(open(INFERENCE_MODEL_PATH + \"/config.json\"))\nid2label = config[\"id2label\"]\n\n#Choose label with max probability\npreds_final = predictions.argmax(-1)\n\n#To try\n# #split predictions of entity to outside entity\n# preds = predictions.argmax(-1)\n# preds_without_O = pred_softmax[:,:,:12].argmax(-1)\n# O_preds = pred_softmax[:,:,12]\n\n# #include NER label if O probability is less than threshold\n# threshold = 0.9\n# preds_final = np.where(O_preds < threshold, preds_without_O , preds)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:43:44.606759Z","iopub.execute_input":"2024-03-01T23:43:44.608400Z","iopub.status.idle":"2024-03-01T23:44:10.829817Z","shell.execute_reply.started":"2024-03-01T23:43:44.608340Z","shell.execute_reply":"2024-03-01T23:44:10.828829Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"markdown","source":"# Process preditions and submit","metadata":{}},{"cell_type":"code","source":"triplets = []\ndocument, token, label, token_str = [], [], [], []\nfor p, token_map, offsets, tokens, doc in zip(preds_final, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n\n    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n        label_pred = id2label[str(token_pred)]\n\n        if start_idx + end_idx == 0: continue\n\n        if token_map[start_idx] == -1:\n            start_idx += 1\n\n        # ignore \"\\n\\n\"\n        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n            start_idx += 1\n\n        if start_idx >= len(token_map): break\n\n        token_id = token_map[start_idx]\n\n        # ignore \"O\" predictions and whitespace preds\n        if label_pred != \"O\" and token_id != -1:\n            triplet = (label_pred, token_id, tokens[token_id])\n\n            if triplet not in triplets:\n                document.append(doc)\n                token.append(token_id)\n                label.append(label_pred)\n                token_str.append(tokens[token_id])\n                triplets.append(triplet)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:46:51.385209Z","iopub.execute_input":"2024-03-01T23:46:51.385784Z","iopub.status.idle":"2024-03-01T23:46:51.472572Z","shell.execute_reply.started":"2024-03-01T23:46:51.385744Z","shell.execute_reply":"2024-03-01T23:46:51.470213Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\n    \"document\": document,\n    \"token\": token,\n    \"label\": label,\n    \"token_str\": token_str\n})\ndf[\"row_id\"] = list(range(len(df)))\ndisplay(df.head(10))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:46:55.385709Z","iopub.execute_input":"2024-03-01T23:46:55.386306Z","iopub.status.idle":"2024-03-01T23:46:55.423359Z","shell.execute_reply.started":"2024-03-01T23:46:55.386250Z","shell.execute_reply":"2024-03-01T23:46:55.421702Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"  document  token           label token_str  row_id\n0        7      9  B-NAME_STUDENT  Nathalie       0\n1        7     10  I-NAME_STUDENT     Sylla       1\n2        7    482  B-NAME_STUDENT  Nathalie       2\n3        7    483  I-NAME_STUDENT     Sylla       3\n4        7    741  B-NAME_STUDENT  Nathalie       4\n5        7    742  I-NAME_STUDENT     Sylla       5\n6       10      0  B-NAME_STUDENT     Diego       6\n7       10      1  I-NAME_STUDENT   Estrada       7\n8       10    464  B-NAME_STUDENT     Diego       8\n9       10    465  I-NAME_STUDENT   Estrada       9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>token</th>\n      <th>label</th>\n      <th>token_str</th>\n      <th>row_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>9</td>\n      <td>B-NAME_STUDENT</td>\n      <td>Nathalie</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>10</td>\n      <td>I-NAME_STUDENT</td>\n      <td>Sylla</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>482</td>\n      <td>B-NAME_STUDENT</td>\n      <td>Nathalie</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>483</td>\n      <td>I-NAME_STUDENT</td>\n      <td>Sylla</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>741</td>\n      <td>B-NAME_STUDENT</td>\n      <td>Nathalie</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>742</td>\n      <td>I-NAME_STUDENT</td>\n      <td>Sylla</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>0</td>\n      <td>B-NAME_STUDENT</td>\n      <td>Diego</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10</td>\n      <td>1</td>\n      <td>I-NAME_STUDENT</td>\n      <td>Estrada</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>464</td>\n      <td>B-NAME_STUDENT</td>\n      <td>Diego</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>465</td>\n      <td>I-NAME_STUDENT</td>\n      <td>Estrada</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"if SUBMISSION:\n    df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:46:59.946957Z","iopub.execute_input":"2024-03-01T23:46:59.948117Z","iopub.status.idle":"2024-03-01T23:46:59.977432Z","shell.execute_reply.started":"2024-03-01T23:46:59.948056Z","shell.execute_reply":"2024-03-01T23:46:59.975248Z"},"trusted":true},"execution_count":22,"outputs":[]}]}